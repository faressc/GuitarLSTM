{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, Dense, ZeroPadding1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.activations import tanh, elu, relu\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import os\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    # Disable all GPUS\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        print(device)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A model with the same name already exists. Please choose a new name.\n"
     ]
    }
   ],
   "source": [
    "# EDIT THIS SECTION FOR USER INPUTS\n",
    "#\n",
    "name = 'model_0'\n",
    "in_file = '../data/ts9_test1_in_FP32.wav'\n",
    "out_file = '../data/ts9_test1_out_FP32.wav'\n",
    "epochs = 1\n",
    "\n",
    "train_mode = 0     # 0 = speed training, \n",
    "                   # 1 = accuracy training \n",
    "                   # 2 = extended training\n",
    "\n",
    "input_size = 150 \n",
    "batch_size = 4096 \n",
    "test_size = 0.2\n",
    "\n",
    "if not os.path.exists('models/'+name):\n",
    "    os.makedirs('models/'+name)\n",
    "else:\n",
    "    print(\"A model with the same name already exists. Please choose a new name.\")\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_emphasis_filter(x, coeff=0.95):\n",
    "    return tf.concat([x, x - coeff * x], 1)\n",
    "    \n",
    "def error_to_signal(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Error to signal ratio with pre-emphasis filter:\n",
    "    \"\"\"\n",
    "    y_true, y_pred = pre_emphasis_filter(y_true), pre_emphasis_filter(y_pred)\n",
    "    return K.sum(tf.pow(y_true - y_pred, 2), axis=0) / (K.sum(tf.pow(y_true, 2), axis=0) + 1e-10)\n",
    "\n",
    "def save_wav(name, data):\n",
    "    wavfile.write(name, 44100, data.flatten().astype(np.float32))\n",
    "\n",
    "def normalize(data):\n",
    "    data_max = max(data)\n",
    "    data_min = min(data)\n",
    "    data_norm = max(data_max,abs(data_min))\n",
    "    return data / data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_training shape: (6587907, 1)\n",
      "X_training shape: (6587907, 1)\n",
      "y_ordered_training shape: (6587758, 1)\n",
      "X_ordered_training shape: (6587758, 150, 1)\n",
      "The X_random_training data is an array, where each element is an array of input_size samples in time order. Therefore the lenght is smaller than the original X_training array (the first 150 samples are grouped).\n",
      "The y_random_training data is an array, where each element is a single sample. This single sample is the target output for the corresponding X_random_training element, which consists of input samples.\n"
     ]
    }
   ],
   "source": [
    "# Load and Preprocess Data ###########################################\n",
    "in_rate, in_data = wavfile.read(in_file)\n",
    "out_rate, out_data = wavfile.read(out_file)\n",
    "\n",
    "X_all = in_data.astype(np.float32).flatten()  \n",
    "X_all = normalize(X_all).reshape(len(X_all),1)   \n",
    "y_all = out_data.astype(np.float32).flatten() \n",
    "y_all = normalize(y_all).reshape(len(y_all),1)\n",
    "\n",
    "# Get the last 20% of the wav data for testing and thee rest for training\n",
    "y_training, y_testing = np.split(y_all, [int(len(y_all)*.8)])\n",
    "X_training, X_testing = np.split(X_all, [int(len(X_all)*.8)])\n",
    "print(f\"y_training shape: {y_training.shape}\")\n",
    "print(f\"X_training shape: {X_training.shape}\")\n",
    "\n",
    "# The input size defines the number of samples used for each prediction\n",
    "# Therefore the first output value that we get is at index input_size-1\n",
    "y_ordered_training = y_training[input_size-1:]\n",
    "print(f\"y_ordered_training shape: {y_ordered_training.shape}\")\n",
    "\n",
    "indices = np.arange(input_size) + np.arange(len(X_training)-input_size+1)[:,np.newaxis]\n",
    "X_ordered_training = tf.gather(X_training,indices) \n",
    "print(f\"X_ordered_training shape: {X_ordered_training.shape}\")\n",
    "\n",
    "shuffled_indices = np.random.permutation(len(X_ordered_training)) \n",
    "X_random_training = tf.gather(X_ordered_training, shuffled_indices)\n",
    "y_random_training = tf.gather(y_ordered_training, shuffled_indices)\n",
    "\n",
    "print(f\"The X_random_training data is an array, where each element is an array of input_size samples in time order. Therefore the lenght is smaller than the original X_training array (the first {input_size} samples are grouped).\")\n",
    "print(f\"The y_random_training data is an array, where each element is a single sample. This single sample is the target output for the corresponding X_random_training element, which consists of input samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding1d (ZeroPaddin  (None, 174, 1)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 14, 16)            208       \n",
      "                                                                 \n",
      " zero_padding1d_1 (ZeroPadd  (None, 38, 16)            0         \n",
      " ing1D)                                                          \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3, 16)             3088      \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 36)                7632      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 37        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10965 (42.83 KB)\n",
      "Trainable params: 10965 (42.83 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "1287/1287 [==============================] - 25s 19ms/step - loss: 8.8380e-04 - error_to_signal: 0.0373 - val_loss: 3.4924e-04 - val_error_to_signal: 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faresschulz/Desktop/ml_repo/GuitarLSTM/tensorflow-version/venv/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "'''This is a similar Tensorflow/Keras implementation of the LSTM model from the paper:\n",
    "    \"Real-Time Guitar Amplifier Emulation with Deep Learning\"\n",
    "    https://www.mdpi.com/2076-3417/10/3/766/htm\n",
    "\n",
    "    Uses a stack of two 1-D Convolutional layers, followed by LSTM, followed by \n",
    "    a Dense (fully connected) layer. Three preset training modes are available, \n",
    "    with further customization by editing the code. A Sequential tf.keras model \n",
    "    is implemented here.\n",
    "\n",
    "    Note: RAM may be a limiting factor for the parameter \"input_size\". The wav data\n",
    "      is preprocessed and stored in RAM, which improves training speed but quickly runs out\n",
    "      if using a large number for \"input_size\".  Reduce this if you are experiencing\n",
    "      RAM issues.\n",
    "'''\n",
    "\n",
    "if train_mode == 0:         # Speed Training\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 12    \n",
    "    conv1d_filters = 16\n",
    "    hidden_units = 36\n",
    "elif train_mode == 1:       # Accuracy Training (~10x longer than Speed Training)\n",
    "    learning_rate = 0.01 \n",
    "    conv1d_strides = 4\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 64\n",
    "else:                       # Extended Training (~60x longer than Accuracy Training)\n",
    "    learning_rate = 0.0005 \n",
    "    conv1d_strides = 3\n",
    "    conv1d_filters = 36\n",
    "    hidden_units= 96\n",
    "\n",
    "\n",
    "# Create Sequential Model ###########################################\n",
    "clear_session()\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding1D(12, input_shape=(input_size,1)))\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None))\n",
    "model.add(ZeroPadding1D(12))\n",
    "model.add(Conv1D(conv1d_filters, 12,strides=conv1d_strides, activation=None))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation=None))\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=[error_to_signal])\n",
    "model.summary()\n",
    "\n",
    "# Train Model ###################################################\n",
    "history = model.fit(X_random_training,y_random_training, epochs=epochs, batch_size=batch_size, validation_split=test_size)     \n",
    "model.save('models/'+name+'/'+name+'.h5')\n",
    "\n",
    "# Add additional data to the saved model (like input_size)\n",
    "filename = 'models/'+name+'/'+name+'.h5'\n",
    "f = h5py.File(filename, 'a')\n",
    "grp = f.create_group(\"info\")\n",
    "dset = grp.create_dataset(\"input_size\", (1,), dtype='int16')\n",
    "dset[0] = input_size\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prediction..\n",
      "403/403 [==============================] - 3s 6ms/step\n",
      "X_testing shape:  (1646977, 1)\n",
      "y_testing shape:  (1646977, 1)\n",
      "prediction shape:  (1646828, 1)\n",
      "Note that the prediction shape is smaller than the y_testing shape. This is because the first predicted sample needs input_size samples for prediction.\n"
     ]
    }
   ],
   "source": [
    "# Run Prediction #################################################\n",
    "print(\"Running prediction..\")\n",
    "\n",
    "indices = np.arange(input_size) + np.arange(len(X_testing)-input_size+1)[:,np.newaxis] \n",
    "X_ordered_testing = tf.gather(X_testing,indices) \n",
    "\n",
    "prediction = model.predict(X_ordered_testing, batch_size=batch_size)\n",
    "\n",
    "save_wav('models/'+name+'/y_pred.wav', prediction)\n",
    "save_wav('models/'+name+'/x_test.wav', X_testing)\n",
    "save_wav('models/'+name+'/y_test.wav', y_testing)\n",
    "\n",
    "print(\"X_testing shape: \", X_testing.shape)\n",
    "print(\"y_testing shape: \", y_testing.shape)\n",
    "print(\"prediction shape: \", prediction.shape)\n",
    "\n",
    "print(\"Note that the prediction shape is smaller than the y_testing shape. This is because the first predicted sample needs input_size samples for prediction.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
